
---
# 卷积
 
## 想法
1. (Automatic Audio Feature Extraction for Keyword Spotting)
换特征提取器，在噪声条件下，可以提高模型效果。  
2. (Maximum-Entropy Adversarial Audio Augmentation for Keyword Spotting)
最大熵对抗方法进行特征增强。  
3. 借鉴下DenseNet?（胡乱的想法）  
4. ~~结合feature-attention~~
5. 加入韵律（持续时间，音高，音强等）信息。
6. 回顾以前看的论文看有没有想法
7. Spectral moment features augmented by low order cepstral coefficients for robust ASR 是更耐噪声的特征
8. 

## 其他待做实验
1. 12分类好好复现成功。(unknown每次都随机抽)



---

# ViT
## 想法
1. 预开题画的模型图。
2. (HViT: Single-Head Vision Transformer with Memory Efficient Macro Design)
换成单头自注意力，减轻模型同时提高效果。

## 其他待做的实验
1. 暂无

---
24.3.29-24.4.4  
调研并实现语音韵律加进特征，（相关文献）(openSMILE, librosa)  
(  
    两个想法，一个是韵律加进fbank特征，输入进一个统一的模型进行建模。另一个想法是两个特征分别建模再送进分类头(这部分借鉴一下跨模态方法？跨模态注意力融合)。  
)    
在上一条基础上用BC-RESNET跑一下，  
实现一个简单基础的baseline做对照  

~~数据集再看再下~~

~~今晚把数据集下载下来，那篇文章再看看~~



librosa.get_duration()获取时常  
librosa.pyin() 提取F0  
librosa.estimate_tuning() 提取音强  

two-way bridge

跑ConvNeXt
跑Vision Mamba






